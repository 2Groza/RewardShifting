{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cda1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: $\\epsilon-greedy$\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 1, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 1, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 1, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 1, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 1, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 1, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 1, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 2, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 1, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 1, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 1, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 1, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 1, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 1, eval_rewards: 1, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 1, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 2, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 1, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 1, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 1, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 1, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 1, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 1, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 1, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 1, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 1, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 1, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 1, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 1, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 2, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 1, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 1, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 1, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 1, eval_rewards: 1, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 1, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "mode: count\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 1, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 1, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 1, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 1, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 1, eval_rewards: 1, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 1, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 2, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 1, eval_rewards: 1, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 1, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 2, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 3, eval_rewards: 1, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 1, eval_rewards: 1, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 7, eval_rewards: 10, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 5, eval_rewards: 5, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 4, eval_rewards: 2, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 2, eval_rewards: 4, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 7, eval_rewards: 8, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 6, eval_rewards: 7, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 8, eval_rewards: 11, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 8, eval_rewards: 3, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 6, eval_rewards: 9, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 6, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 8, eval_rewards: 23, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 24, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 8, eval_rewards: 42, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 30, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 21, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 43, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 21, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 33, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 47, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 49, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 1, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 1, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 1, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 1, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 1, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 2, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 3, eval_rewards: 1, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 1, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 1, eval_rewards: 9, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 2, eval_rewards: 7, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 1, eval_rewards: 1, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 3, eval_rewards: 2, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 2, eval_rewards: 10, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 4, eval_rewards: 5, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 4, eval_rewards: 2, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 5, eval_rewards: 12, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 8, eval_rewards: 8, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 9, eval_rewards: 18, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 6, eval_rewards: 4, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 5, eval_rewards: 15, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 7, eval_rewards: 13, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 9, eval_rewards: 25, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 9, eval_rewards: 21, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 12, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 26, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 7, eval_rewards: 30, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 31, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 48, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 46, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 49, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 49, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 47, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 49, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 1, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 2, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 1, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 1, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 1, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 1, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 1, eval_rewards: 3, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 3, eval_rewards: 3, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 5, eval_rewards: 4, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 4, eval_rewards: 5, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 3, eval_rewards: 2, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 4, eval_rewards: 15, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 6, eval_rewards: 2, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 5, eval_rewards: 5, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 7, eval_rewards: 7, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 5, eval_rewards: 15, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 7, eval_rewards: 21, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 9, eval_rewards: 32, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 9, eval_rewards: 22, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 9, eval_rewards: 33, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 9, eval_rewards: 42, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 9, eval_rewards: 41, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 9, eval_rewards: 48, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 46, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 48, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 49, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 1, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 1, eps:0.6799999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 1, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 1, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 1, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 1, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 1, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 2, eval_rewards: 1, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 2, eval_rewards: 3, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 3, eval_rewards: 11, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 1, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 4, eval_rewards: 2, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 5, eval_rewards: 9, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 3, eval_rewards: 16, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 6, eval_rewards: 15, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 5, eval_rewards: 5, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 8, eval_rewards: 14, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 8, eval_rewards: 18, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 13, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 9, eval_rewards: 35, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 7, eval_rewards: 30, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 17, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 9, eval_rewards: 36, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 39, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 45, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 49, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 48, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 1, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 1, eps:0.7299999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 1, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 1, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 1, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 1, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 1, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 1, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 1, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 1, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 2, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 1, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 2, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 2, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 1, eval_rewards: 1, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 1, eval_rewards: 2, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 3, eval_rewards: 9, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 2, eval_rewards: 3, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 2, eval_rewards: 3, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 2, eval_rewards: 9, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 3, eval_rewards: 3, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 4, eval_rewards: 17, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 6, eval_rewards: 2, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 6, eval_rewards: 19, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 7, eval_rewards: 19, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 7, eval_rewards: 11, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 6, eval_rewards: 24, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 5, eval_rewards: 13, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 6, eval_rewards: 18, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 9, eval_rewards: 14, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 8, eval_rewards: 3, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 7, eval_rewards: 43, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 9, eval_rewards: 18, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 6, eval_rewards: 33, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 31, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 9, eval_rewards: 44, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 37, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 9, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 42, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 48, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 49, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 49, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 1, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 1, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 1, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 1, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 1, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 1, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 2, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 2, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 2, eval_rewards: 1, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 2, eval_rewards: 11, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 2, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 3, eval_rewards: 12, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 3, eval_rewards: 24, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 3, eval_rewards: 25, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 7, eval_rewards: 25, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 3, eval_rewards: 24, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 6, eval_rewards: 23, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 7, eval_rewards: 36, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 7, eval_rewards: 39, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 8, eval_rewards: 39, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 9, eval_rewards: 40, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 40, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 8, eval_rewards: 46, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 9, eval_rewards: 46, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 8, eval_rewards: 47, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 8, eval_rewards: 47, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 48, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 9, eval_rewards: 42, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 48, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 9, eval_rewards: 49, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 9, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 9, eval_rewards: 46, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 9, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 48, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 9, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 1, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 3, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 2, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 1, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 1, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 2, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 1, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 2, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 1, eval_rewards: 5, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 3, eval_rewards: 3, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 1, eval_rewards: 11, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 14, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 4, eval_rewards: 14, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 4, eval_rewards: 12, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 8, eval_rewards: 14, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 4, eval_rewards: 7, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 6, eval_rewards: 31, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 8, eval_rewards: 13, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 9, eval_rewards: 23, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 9, eval_rewards: 33, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 9, eval_rewards: 31, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 8, eval_rewards: 34, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 47, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 49, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 49, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 49, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 48, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 48, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 49, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 1, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 1, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 1, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 1, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 1, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 1, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 1, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 4, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 1, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 1, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 1, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 1, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 1, eval_rewards: 3, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 5, eval_rewards: 6, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 3, eval_rewards: 4, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 3, eval_rewards: 4, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 7, eval_rewards: 7, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 4, eval_rewards: 14, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 5, eval_rewards: 16, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 7, eval_rewards: 13, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 6, eval_rewards: 5, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 6, eval_rewards: 24, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 8, eval_rewards: 12, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 8, eval_rewards: 38, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 9, eval_rewards: 9, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 24, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 9, eval_rewards: 32, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 9, eval_rewards: 35, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 43, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 49, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 48, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 49, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 48, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 0, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 0, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 1, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 1, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 1, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 1, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 1, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 1, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 0, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 1, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 1, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 1, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 1, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 0, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 0, eval_rewards: 0, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 0, eval_rewards: 0, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 0, eval_rewards: 0, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 0, eval_rewards: 0, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 0, eval_rewards: 0, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 0, eval_rewards: 0, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 0, eval_rewards: 0, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 0, eval_rewards: 0, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 0, eval_rewards: 0, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 0, eval_rewards: 0, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 0, eval_rewards: 0, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 0, eval_rewards: 0, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 0, eval_rewards: 0, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 0, eval_rewards: 0, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 0, eval_rewards: 0, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 0, eval_rewards: 0, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 0, eval_rewards: 0, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 0, eval_rewards: 0, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 0, eval_rewards: 0, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 0, eval_rewards: 0, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 0, eval_rewards: 0, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 0, eval_rewards: 0, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 0, eval_rewards: 0, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 0, eval_rewards: 0, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 0, eval_rewards: 0, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 0, eval_rewards: 0, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 0, eval_rewards: 0, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 0, eval_rewards: 0, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 0, eval_rewards: 0, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 0, eval_rewards: 0, eps:0\n",
      "count matrix: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 0, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 0, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 1, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 0, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 0, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 0, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 0, eval_rewards: 0, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 0, eval_rewards: 0, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 0, eval_rewards: 0, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 0, eval_rewards: 0, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 0, eval_rewards: 0, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 0, eval_rewards: 0, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 0, eval_rewards: 0, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 0, eval_rewards: 0, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 0, eval_rewards: 0, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 0, eval_rewards: 0, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 0, eval_rewards: 0, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 0, eval_rewards: 0, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 0, eval_rewards: 0, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 0, eval_rewards: 0, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 0, eval_rewards: 0, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 0, eval_rewards: 0, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 0, eval_rewards: 0, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 0, eval_rewards: 1, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 0, eval_rewards: 0, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 0, eval_rewards: 0, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 0, eval_rewards: 0, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 0, eval_rewards: 0, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 0, eval_rewards: 0, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 0, eval_rewards: 0, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 0, eval_rewards: 0, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 0, eval_rewards: 0, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 0, eval_rewards: 0, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 0, eval_rewards: 0, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 0, eval_rewards: 0, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 0, eval_rewards: 0, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 0, eval_rewards: 0, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 0, eval_rewards: 0, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 0, eval_rewards: 3, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 1, eval_rewards: 1, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 3, eval_rewards: 1, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 3, eval_rewards: 2, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 4, eval_rewards: 2, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 6, eval_rewards: 2, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 6, eval_rewards: 5, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 3, eval_rewards: 16, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 8, eval_rewards: 4, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 4, eval_rewards: 9, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 6, eval_rewards: 4, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 7, eval_rewards: 19, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 9, eval_rewards: 10, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 17, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 8, eval_rewards: 16, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 14, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 9, eval_rewards: 35, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 22, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 25, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 40, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 48, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 40, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 49, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 49, eps:0.049999999999999156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 49, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 48, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 49, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "mode: reward shift -0.02\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 1, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 1, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 1, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 1, eval_rewards: 2, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 1, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 1, eval_rewards: 1, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 1, eval_rewards: 2, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 1, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 3, eval_rewards: 7, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 2, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 2, eval_rewards: 4, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 2, eval_rewards: 8, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 1, eval_rewards: 4, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 1, eval_rewards: 7, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 2, eval_rewards: 10, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 5, eval_rewards: 18, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 3, eval_rewards: 23, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 4, eval_rewards: 27, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 4, eval_rewards: 32, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 4, eval_rewards: 29, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 5, eval_rewards: 29, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 7, eval_rewards: 38, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 8, eval_rewards: 31, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 7, eval_rewards: 40, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 8, eval_rewards: 35, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 9, eval_rewards: 41, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 41, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 7, eval_rewards: 47, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 46, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 8, eval_rewards: 47, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 9, eval_rewards: 49, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 47, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 8, eval_rewards: 49, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 49, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 1, eval_rewards: 1, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 1, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 1, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 1, eval_rewards: 2, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 2, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 2, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 1, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 1, eval_rewards: 1, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 3, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 1, eval_rewards: 4, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 1, eval_rewards: 5, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 7, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 1, eval_rewards: 7, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 9, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 4, eval_rewards: 8, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 2, eval_rewards: 19, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 6, eval_rewards: 15, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 3, eval_rewards: 16, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 6, eval_rewards: 24, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 5, eval_rewards: 16, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 3, eval_rewards: 22, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 7, eval_rewards: 26, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 6, eval_rewards: 16, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 6, eval_rewards: 41, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 7, eval_rewards: 32, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 6, eval_rewards: 33, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 8, eval_rewards: 41, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 7, eval_rewards: 41, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 7, eval_rewards: 39, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 43, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 45, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 47, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 49, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 47, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 48, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 49, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 49, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 1, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 1, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 1, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 1, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 3, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 2, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 1, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 0, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 1, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 2, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 2, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 3, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 5, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 4, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 1, eval_rewards: 4, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 7, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 2, eval_rewards: 15, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 1, eval_rewards: 15, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 2, eval_rewards: 16, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 4, eval_rewards: 19, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 3, eval_rewards: 17, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 2, eval_rewards: 21, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 5, eval_rewards: 34, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 3, eval_rewards: 30, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 3, eval_rewards: 34, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 7, eval_rewards: 38, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 7, eval_rewards: 33, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 8, eval_rewards: 42, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 9, eval_rewards: 37, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 7, eval_rewards: 45, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 42, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 7, eval_rewards: 44, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 9, eval_rewards: 43, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 43, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 9, eval_rewards: 49, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 47, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 49, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 9, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 49, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 49, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 1, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 1, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 1, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 2, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 3, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 3, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 3, eval_rewards: 4, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 6, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 6, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 2, eval_rewards: 16, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 3, eval_rewards: 8, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 2, eval_rewards: 11, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 6, eval_rewards: 10, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 6, eval_rewards: 11, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 4, eval_rewards: 17, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 4, eval_rewards: 22, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 6, eval_rewards: 21, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 7, eval_rewards: 16, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 7, eval_rewards: 29, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 34, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 8, eval_rewards: 36, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 8, eval_rewards: 37, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 7, eval_rewards: 27, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 8, eval_rewards: 40, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 9, eval_rewards: 43, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 8, eval_rewards: 40, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 8, eval_rewards: 48, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 46, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 39, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 9, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 49, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 49, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 49, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 49, eps:0.26999999999999935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 1, eval_rewards: 2, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 1, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 1, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 2, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 2, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 1, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 2, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 1, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 3, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 1, eval_rewards: 7, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 5, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 1, eval_rewards: 4, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 1, eval_rewards: 3, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 3, eval_rewards: 6, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 2, eval_rewards: 15, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 4, eval_rewards: 11, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 3, eval_rewards: 18, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 7, eval_rewards: 19, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 7, eval_rewards: 15, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 5, eval_rewards: 23, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 3, eval_rewards: 25, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 4, eval_rewards: 17, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 5, eval_rewards: 35, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 7, eval_rewards: 32, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 7, eval_rewards: 37, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 45, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 44, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 40, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 8, eval_rewards: 38, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 47, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 9, eval_rewards: 45, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 49, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 9, eval_rewards: 48, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 49, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 49, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 49, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 49, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 0, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 1, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 2, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 1, eval_rewards: 2, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 3, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 2, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 2, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 2, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 10, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 1, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 1, eval_rewards: 7, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 3, eval_rewards: 3, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 2, eval_rewards: 13, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 2, eval_rewards: 18, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 3, eval_rewards: 14, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 3, eval_rewards: 14, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 4, eval_rewards: 14, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 3, eval_rewards: 15, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 4, eval_rewards: 24, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 6, eval_rewards: 19, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 5, eval_rewards: 28, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 4, eval_rewards: 30, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 4, eval_rewards: 28, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 7, eval_rewards: 30, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 8, eval_rewards: 36, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 8, eval_rewards: 35, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 8, eval_rewards: 46, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 44, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 47, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 9, eval_rewards: 49, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 49, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 47, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 47, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 9, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 49, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 49, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 49, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 9, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 49, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 1, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 1, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 1, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 4, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 1, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 1, eval_rewards: 1, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 3, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 1, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 2, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 4, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 2, eval_rewards: 3, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 0, eval_rewards: 6, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 2, eval_rewards: 8, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 2, eval_rewards: 15, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 3, eval_rewards: 21, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 2, eval_rewards: 15, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 3, eval_rewards: 14, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 5, eval_rewards: 26, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 3, eval_rewards: 24, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 5, eval_rewards: 26, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 9, eval_rewards: 39, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 7, eval_rewards: 37, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 6, eval_rewards: 25, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 9, eval_rewards: 39, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 7, eval_rewards: 40, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 9, eval_rewards: 48, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 7, eval_rewards: 42, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 8, eval_rewards: 45, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 45, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 8, eval_rewards: 48, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 48, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 48, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 44, eps:0.4399999999999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 49, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 47, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 49, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 1, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 2, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 3, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 1, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 0, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 2, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 1, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 3, eval_rewards: 1, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 0, eval_rewards: 3, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 2, eval_rewards: 7, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 2, eval_rewards: 2, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 0, eval_rewards: 15, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 1, eval_rewards: 11, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 5, eval_rewards: 13, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 2, eval_rewards: 14, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 2, eval_rewards: 12, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 1, eval_rewards: 18, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 3, eval_rewards: 19, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 2, eval_rewards: 29, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 8, eval_rewards: 25, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 9, eval_rewards: 27, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 9, eval_rewards: 27, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 7, eval_rewards: 39, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 7, eval_rewards: 38, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 7, eval_rewards: 41, eps:0.49999999999999956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 47, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 37, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 45, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 9, eval_rewards: 46, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 47, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 48, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 47, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 9, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 47, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 49, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 1, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 1, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 0, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 0, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 0, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 1, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 0, eval_rewards: 0, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 2, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 2, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 1, eval_rewards: 0, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 0, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 1, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 0, eval_rewards: 4, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 2, eval_rewards: 6, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 4, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 1, eval_rewards: 11, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 2, eval_rewards: 12, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 3, eval_rewards: 11, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 5, eval_rewards: 14, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 1, eval_rewards: 12, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 3, eval_rewards: 16, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 5, eval_rewards: 9, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 5, eval_rewards: 22, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 3, eval_rewards: 28, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 1, eval_rewards: 31, eps:0.5599999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 450, train mean_rewards: 9, eval_rewards: 23, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 6, eval_rewards: 35, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 6, eval_rewards: 33, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 35, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 6, eval_rewards: 42, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 5, eval_rewards: 36, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 44, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 43, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 47, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 9, eval_rewards: 47, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 9, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 49, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 46, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 47, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 49, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 0, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 0, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 0, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 0, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 0, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 0, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 0, eval_rewards: 0, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 0, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 0, eval_rewards: 0, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 0, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 0, eval_rewards: 0, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 0, eval_rewards: 0, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 0, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 0, eval_rewards: 0, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 0, eval_rewards: 0, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 0, eval_rewards: 1, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 1, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 0, eval_rewards: 0, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 0, eval_rewards: 0, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 0, eval_rewards: 1, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 0, eval_rewards: 3, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 0, eval_rewards: 0, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 0, eval_rewards: 0, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 1, eval_rewards: 1, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 0, eval_rewards: 1, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 0, eval_rewards: 1, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 0, eval_rewards: 1, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 0, eval_rewards: 2, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 0, eval_rewards: 3, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 2, eval_rewards: 2, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 0, eval_rewards: 4, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 8, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 1, eval_rewards: 2, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 0, eval_rewards: 11, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 2, eval_rewards: 6, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 4, eval_rewards: 10, eps:0.6199999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 390, train mean_rewards: 4, eval_rewards: 2, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 4, eval_rewards: 14, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 3, eval_rewards: 21, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 5, eval_rewards: 18, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 1, eval_rewards: 20, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 5, eval_rewards: 24, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 7, eval_rewards: 24, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 6, eval_rewards: 25, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 4, eval_rewards: 35, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 8, eval_rewards: 39, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 9, eval_rewards: 40, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 8, eval_rewards: 44, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 40, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 43, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 45, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 9, eval_rewards: 34, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 9, eval_rewards: 45, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 9, eval_rewards: 49, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 48, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from asyncore import readwrite\n",
    "from os import environ\n",
    "from unittest.util import _count_diff_all_purpose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "class GridEnv():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.state = np.array([0,0])\n",
    "        self.action = np.array([0,0])\n",
    "        self.goal = np.array([size-1, size-1])\n",
    "        self.horizon = 100\n",
    "        self.steps = 0\n",
    "        self.action_dict = {\n",
    "            0: np.array([1,0]),\n",
    "            1: np.array([0,1]),\n",
    "            2: np.array([-1,0]),\n",
    "            3: np.array([0,-1]),\n",
    "        }\n",
    "\n",
    "    def _process_action(self, action):\n",
    "        assert 0 <= action <= 3, 'Action error {}!'.format(action)\n",
    "        if type(action) != int:\n",
    "            action = int(action)\n",
    "        return self.action_dict[action]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0])\n",
    "        self.goal = np.array([self.size-1, self.size-1])\n",
    "        self.steps = 0\n",
    "        return self.state.copy()\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = self._process_action(action)\n",
    "        self.state += action\n",
    "        self.state = np.clip(self.state, 0, self.size-1)\n",
    "        if np.all(self.state == self.goal):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.steps += 1\n",
    "        done = False\n",
    "        if self.steps >= self.horizon or reward == 1:\n",
    "            done = True \n",
    "        info = {}\n",
    "        return self.state.copy(), reward, done, info \n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, num_action=4, eps_greedy=True, mode='', gamma=0.99):\n",
    "        self.state_size = state_size\n",
    "        self.num_action = num_action\n",
    "        self.Q_values = np.zeros((state_size, state_size, num_action))  \n",
    "        self.eps_greedy = eps_greedy\n",
    "        self.eps_init = 1\n",
    "        self.eps = self.eps_init\n",
    "        self.eps_decay = 0.001  \n",
    "        self.learning_rate = 1\n",
    "        self.gamma = gamma\n",
    "        # mode\n",
    "        self.mode = mode\n",
    "        if mode == 'opt_init':\n",
    "            self.Q_values += 1\n",
    "            print('Q_value: {}'.format(self.Q_values.mean()))\n",
    "        elif mode == 'count':\n",
    "            # count\n",
    "            self.count_matrix = np.zeros((state_size, state_size))\n",
    "            print('count matrix: {}'.format(self.count_matrix.mean()))\n",
    "        elif mode.startswith('reward shift'):\n",
    "            self.reward_shift = float(mode.replace('reward shift ', ''))\n",
    "            print('reward shift {}'.format(self.reward_shift))\n",
    "        else:\n",
    "            print('no mode')\n",
    "\n",
    "    \n",
    "    def _decay_eps(self):\n",
    "        self.eps = max(0, self.eps - self.eps_decay)\n",
    "    \n",
    "    def act(self, state, random=False):\n",
    "        if self.mode == 'count':\n",
    "            self.count_matrix[state[0], state[1]] += 1\n",
    "\n",
    "        if random or (self.eps_greedy and np.random.random() < self.eps):\n",
    "            return np.random.randint(self.num_action)\n",
    "        argmax_action = np.argmax(self.Q_values[state[0], state[1]])\n",
    "        return argmax_action\n",
    "\n",
    "    def update_Q(self, transition):\n",
    "        state, action, next_state, reward, done = transition\n",
    "        argmax_action = np.argmax(self.Q_values[next_state[0], next_state[1]])\n",
    "\n",
    "        if self.mode.startswith('reward shift'):\n",
    "            reward  += self.reward_shift\n",
    "        elif self.mode == 'count':\n",
    "            reward += 1 / (self.count_matrix[state[0], state[1]] + 1) * 0.1\n",
    "\n",
    "        self.Q_values[state[0], state[1]][action] += self.learning_rate * (reward + \n",
    "                        self.gamma * self.Q_values[next_state[0], next_state[1]][argmax_action] - self.Q_values[state[0], state[1]][action])\n",
    "\n",
    "def rollout(agent, env, episode=10, eval=False):\n",
    "    reward_list = []\n",
    "    for _ in range(episode):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        rewards = 0\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            if not eval:\n",
    "                agent.update_Q([state, action, next_state, reward, done])\n",
    "            rewards += reward\n",
    "            state = next_state\n",
    "        reward_list.append(rewards)\n",
    "        if not eval:\n",
    "            agent._decay_eps()\n",
    "    return np.sum(reward_list)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_curves = True # if false, plot heatmap\n",
    "    size = 20  # set the map size\n",
    "    print_every = 10\n",
    "\n",
    "    if plot_curves:\n",
    "        num_seed = 10\n",
    "        num_episode = 1000 \n",
    "        eval_episodes = 50  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02'] # 'opt_init', 'reward shift -0.1'\n",
    "    else:\n",
    "        num_seed = 1\n",
    "        num_episode = 1500\n",
    "        eval_episodes = 10  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02', 'reward shift -0.1'] # 'opt_init', \n",
    "    \n",
    "    result_all_list = []\n",
    "    for j, mode in enumerate(mode_list):\n",
    "        print('mode: {}'.format(mode))\n",
    "        result_seed = []\n",
    "        for seed in range(num_seed):\n",
    "            result = []\n",
    "            env = GridEnv(size=size)\n",
    "            agent = Agent(state_size=size, mode=mode)\n",
    "            for i in range(num_episode // print_every):\n",
    "                train_rewards = rollout(agent, env, episode=print_every)\n",
    "                eval_rewards = rollout(agent, env, eval=True, episode=eval_episodes)\n",
    "                print('training episodes: {}, train mean_rewards: {}, eval_rewards: {}, eps:{}'.format((i+1)* print_every,\n",
    "                                    train_rewards, eval_rewards, agent.eps))\n",
    "                result.append(eval_rewards)\n",
    "            result_seed.append(result)\n",
    "        \n",
    "        result_all_list.append(result_seed)\n",
    "\n",
    "        # plot heatmap\n",
    "        if not plot_curves:\n",
    "            plt.subplot(1,len(mode_list), j+1) \n",
    "            # normalize Q values\n",
    "            Q_values = agent.Q_values.max(axis=2).copy()\n",
    "            Q_max, Q_min = Q_values.max(), Q_values.min()\n",
    "            if Q_max == Q_min:\n",
    "                Q_values_norm = np.zeros(Q_values.shape)\n",
    "            else:\n",
    "                Q_values_norm = (Q_values - Q_min) / (Q_max - Q_min)\n",
    "            sns.heatmap(data=Q_values_norm, square=True, vmin=0, vmax=1) \n",
    "            plt.title(mode)\n",
    "    \n",
    "    if not plot_curves:\n",
    "        plt.show()\n",
    "    else:\n",
    "        x_axis = (np.arange(num_episode // print_every) + 1) * print_every\n",
    "        for i, mode in enumerate(mode_list):\n",
    "            if type(result_all_list[i][0]) == list:\n",
    "                array = np.array(result_all_list[i])\n",
    "                y_mean = array.mean(axis=0)\n",
    "                y_std = array.std(axis=0)\n",
    "                plt.plot(x_axis, y_mean, label=mode)\n",
    "                plt.fill_between(x_axis, y_mean - y_std, y_mean + y_std, alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(x_axis, result_all_list[i], label=mode)\n",
    "        plt.legend()\n",
    "        plt.title(r'Exploration in {} $\\times$ {} Grid World'.format(size, size))\n",
    "        plt.ylabel('Evaluation Returns')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.show()\n",
    "\n",
    "        # save\n",
    "        np.save('grid_return_{}.npy'.format(size), np.array(result_all_list))\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ef7e6",
   "metadata": {},
   "source": [
    "# goal = 5/10/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5090bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: $\\epsilon-greedy$\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 3, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 6, eval_rewards: 22, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 28, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 3, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 2, eval_rewards: 24, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 30, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 37, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 32, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 32, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 35, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 38, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 41, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 9, eval_rewards: 40, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 6, eval_rewards: 39, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 10, eval_rewards: 47, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 38, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 42, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 7, eval_rewards: 43, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 44, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 9, eval_rewards: 46, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 45, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 45, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 9, eval_rewards: 46, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 46, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 9, eval_rewards: 50, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 50, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 48, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 48, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 47, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 46, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 49, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 49, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 49, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 49, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 49, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 5, eval_rewards: 18, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 24, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 25, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 5, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 24, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 27, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 3, eval_rewards: 33, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 5, eval_rewards: 38, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 38, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 38, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 33, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 9, eval_rewards: 33, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 6, eval_rewards: 41, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 47, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 45, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 6, eval_rewards: 46, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 10, eval_rewards: 39, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 47, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 8, eval_rewards: 46, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 49, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 42, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 42, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 8, eval_rewards: 46, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 49, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 50, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 8, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 47, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 50, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 49, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 5, eval_rewards: 20, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 27, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 25, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 7, eval_rewards: 28, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 29, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 26, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 28, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 3, eval_rewards: 33, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 41, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 37, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 40, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 38, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 9, eval_rewards: 37, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 41, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 9, eval_rewards: 39, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 47, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 46, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 42, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 47, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 8, eval_rewards: 45, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 50, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 9, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 45, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 9, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 50, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 49, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 48, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 9, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 2, eval_rewards: 19, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 3, eval_rewards: 22, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 4, eval_rewards: 27, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 21, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 8, eval_rewards: 31, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 35, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 8, eval_rewards: 32, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 31, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 5, eval_rewards: 33, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 5, eval_rewards: 35, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 37, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 38, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 41, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 9, eval_rewards: 41, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 9, eval_rewards: 44, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 9, eval_rewards: 45, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 39, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 44, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 10, eval_rewards: 46, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 43, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 47, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 45, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 49, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 50, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 9, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 48, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 50, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 49, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 47, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 49, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 8, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 3, eval_rewards: 20, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 3, eval_rewards: 21, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 26, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 32, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 32, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 32, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 9, eval_rewards: 36, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 7, eval_rewards: 33, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 7, eval_rewards: 44, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 46, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 7, eval_rewards: 36, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 8, eval_rewards: 46, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 40, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 7, eval_rewards: 48, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 46, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 42, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 40, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 8, eval_rewards: 46, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 7, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 48, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 48, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 48, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 49, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 50, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 50, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 49, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 9, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 25, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 2, eval_rewards: 22, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 9, eval_rewards: 30, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 2, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 7, eval_rewards: 33, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 34, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 30, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 35, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 35, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 39, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 5, eval_rewards: 38, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 37, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 7, eval_rewards: 38, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 38, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 6, eval_rewards: 41, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 44, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 40, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 10, eval_rewards: 40, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 7, eval_rewards: 48, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 47, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 44, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 6, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 45, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 9, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 47, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 47, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 48, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 49, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 48, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 49, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 49, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 3, eval_rewards: 24, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 6, eval_rewards: 30, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 31, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 30, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 7, eval_rewards: 32, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 33, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 34, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 5, eval_rewards: 35, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 29, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 32, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 36, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 37, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 37, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 39, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 42, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 8, eval_rewards: 39, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 39, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 43, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 45, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 8, eval_rewards: 48, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 50, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 46, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 9, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 49, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 47, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 49, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 49, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 49, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 49, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 22, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 20, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 3, eval_rewards: 24, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 7, eval_rewards: 28, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 8, eval_rewards: 29, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 6, eval_rewards: 25, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 42, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 34, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 7, eval_rewards: 36, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 33, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 38, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 36, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 43, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 8, eval_rewards: 41, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 9, eval_rewards: 36, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 43, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 8, eval_rewards: 45, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 8, eval_rewards: 46, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 44, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 43, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 50, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 49, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 48, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 48, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 49, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 48, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 49, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 2, eval_rewards: 19, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 7, eval_rewards: 30, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 8, eval_rewards: 22, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 1, eval_rewards: 24, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 7, eval_rewards: 35, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 6, eval_rewards: 25, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 4, eval_rewards: 31, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 9, eval_rewards: 30, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 33, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 40, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 30, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 42, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 35, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 41, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 43, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 10, eval_rewards: 45, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 45, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 10, eval_rewards: 46, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 46, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 44, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 8, eval_rewards: 48, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 50, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 9, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 47, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 46, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 49, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 49, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 4, eval_rewards: 18, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 16, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 25, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 5, eval_rewards: 24, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 1, eval_rewards: 30, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 26, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 4, eval_rewards: 26, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 31, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 37, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 35, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 33, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 35, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 7, eval_rewards: 39, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 10, eval_rewards: 40, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 6, eval_rewards: 43, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 39, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 8, eval_rewards: 45, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 41, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 10, eval_rewards: 46, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 9, eval_rewards: 43, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 47, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 9, eval_rewards: 46, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 8, eval_rewards: 49, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 8, eval_rewards: 48, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 48, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 49, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 49, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "mode: count\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 5, eval_rewards: 24, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 6, eval_rewards: 20, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 28, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 8, eval_rewards: 19, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 27, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 2, eval_rewards: 31, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 31, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 2, eval_rewards: 32, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 24, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 19, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 3, eval_rewards: 16, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 22, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 2, eval_rewards: 21, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 6, eval_rewards: 24, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 6, eval_rewards: 33, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 6, eval_rewards: 25, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 6, eval_rewards: 33, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 32, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 5, eval_rewards: 38, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 8, eval_rewards: 29, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 7, eval_rewards: 36, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 8, eval_rewards: 36, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 5, eval_rewards: 38, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 7, eval_rewards: 38, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 7, eval_rewards: 39, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 9, eval_rewards: 41, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 45, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 46, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 43, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 8, eval_rewards: 45, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 43, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 45, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 48, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 46, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 48, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 8, eval_rewards: 48, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 49, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 49, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 49, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 9, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 48, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 48, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 49, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 9, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 5, eval_rewards: 27, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 21, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 4, eval_rewards: 18, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 22, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 21, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 7, eval_rewards: 28, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 26, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 29, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 20, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 18, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 3, eval_rewards: 15, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 5, eval_rewards: 20, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 6, eval_rewards: 16, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 5, eval_rewards: 21, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 4, eval_rewards: 26, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 4, eval_rewards: 14, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 1, eval_rewards: 13, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 3, eval_rewards: 21, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 5, eval_rewards: 31, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 8, eval_rewards: 31, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 3, eval_rewards: 29, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 6, eval_rewards: 36, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 6, eval_rewards: 39, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 5, eval_rewards: 39, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 8, eval_rewards: 38, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 6, eval_rewards: 38, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 43, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 5, eval_rewards: 38, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 8, eval_rewards: 42, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 7, eval_rewards: 38, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 41, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 44, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 44, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 46, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 44, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 7, eval_rewards: 42, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 43, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 8, eval_rewards: 45, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 43, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 43, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 49, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 49, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 8, eval_rewards: 44, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 46, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 9, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 49, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 49, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 46, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 9, eval_rewards: 46, eps:0.49999999999999956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 49, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 49, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 49, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 49, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 49, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 49, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 49, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 2, eval_rewards: 20, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 7, eval_rewards: 21, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 7, eval_rewards: 24, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 5, eval_rewards: 30, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 8, eval_rewards: 24, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 30, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 8, eval_rewards: 35, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 40, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 39, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 5, eval_rewards: 40, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 9, eval_rewards: 34, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 40, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 39, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 10, eval_rewards: 38, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 44, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 37, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 7, eval_rewards: 49, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 43, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 8, eval_rewards: 44, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 45, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 47, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 8, eval_rewards: 46, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 45, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 49, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 48, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 48, eps:0.5699999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 3, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 6, eval_rewards: 17, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 3, eval_rewards: 25, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 25, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 27, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 2, eval_rewards: 24, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 4, eval_rewards: 29, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 23, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 5, eval_rewards: 27, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 28, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 25, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 28, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 3, eval_rewards: 26, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 6, eval_rewards: 25, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 3, eval_rewards: 25, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 6, eval_rewards: 17, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 2, eval_rewards: 23, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 5, eval_rewards: 12, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 2, eval_rewards: 11, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 4, eval_rewards: 15, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 4, eval_rewards: 18, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 5, eval_rewards: 16, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 3, eval_rewards: 18, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 2, eval_rewards: 17, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 2, eval_rewards: 23, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 2, eval_rewards: 19, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 4, eval_rewards: 16, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 4, eval_rewards: 16, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 1, eval_rewards: 12, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 2, eval_rewards: 11, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 3, eval_rewards: 7, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 3, eval_rewards: 10, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 1, eval_rewards: 16, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 4, eval_rewards: 24, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 5, eval_rewards: 16, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 3, eval_rewards: 38, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 4, eval_rewards: 28, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 5, eval_rewards: 30, eps:0.6199999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 390, train mean_rewards: 6, eval_rewards: 34, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 6, eval_rewards: 36, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 7, eval_rewards: 40, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 8, eval_rewards: 38, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 6, eval_rewards: 42, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 9, eval_rewards: 44, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 43, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 8, eval_rewards: 45, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 8, eval_rewards: 42, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 8, eval_rewards: 41, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 8, eval_rewards: 44, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 9, eval_rewards: 43, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 46, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 46, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 9, eval_rewards: 46, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 45, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 48, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 9, eval_rewards: 45, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 9, eval_rewards: 48, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 46, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 47, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 9, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 48, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 42, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 48, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 49, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 48, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 48, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 9, eval_rewards: 49, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 9, eval_rewards: 48, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 49, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 9, eval_rewards: 47, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 8, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 49, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 48, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 48, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 49, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 9, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 9, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 49, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 27, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 2, eval_rewards: 21, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 22, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 7, eval_rewards: 23, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 20, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 6, eval_rewards: 28, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 9, eval_rewards: 24, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 4, eval_rewards: 16, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 4, eval_rewards: 32, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 7, eval_rewards: 26, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 27, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 27, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 3, eval_rewards: 27, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 6, eval_rewards: 25, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 7, eval_rewards: 21, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 5, eval_rewards: 19, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 3, eval_rewards: 21, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 7, eval_rewards: 30, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 5, eval_rewards: 30, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 3, eval_rewards: 35, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 7, eval_rewards: 38, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 7, eval_rewards: 39, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 7, eval_rewards: 35, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 45, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 7, eval_rewards: 40, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 8, eval_rewards: 43, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 8, eval_rewards: 47, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 37, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 42, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 45, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 44, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 44, eps:0.6799999999999997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 42, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 44, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 47, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 9, eval_rewards: 48, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 9, eval_rewards: 44, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 8, eval_rewards: 45, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 49, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 49, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 45, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 46, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 47, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 47, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 46, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 47, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 46, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 9, eval_rewards: 48, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 47, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 9, eval_rewards: 49, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 48, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 49, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 48, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 48, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 48, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 49, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 49, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 49, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 7, eval_rewards: 22, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 26, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 26, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 20, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 25, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 3, eval_rewards: 24, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 22, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 28, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 27, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 3, eval_rewards: 14, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 5, eval_rewards: 29, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 22, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 6, eval_rewards: 23, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 4, eval_rewards: 23, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 3, eval_rewards: 23, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 3, eval_rewards: 17, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 4, eval_rewards: 25, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 2, eval_rewards: 20, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 4, eval_rewards: 9, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 2, eval_rewards: 9, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 3, eval_rewards: 21, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 3, eval_rewards: 17, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 4, eval_rewards: 13, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 4, eval_rewards: 21, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 7, eval_rewards: 29, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 4, eval_rewards: 31, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 6, eval_rewards: 30, eps:0.7299999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 280, train mean_rewards: 4, eval_rewards: 33, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 7, eval_rewards: 39, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 8, eval_rewards: 32, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 7, eval_rewards: 34, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 7, eval_rewards: 34, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 8, eval_rewards: 30, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 8, eval_rewards: 29, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 38, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 7, eval_rewards: 45, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 5, eval_rewards: 42, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 44, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 9, eval_rewards: 44, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 45, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 9, eval_rewards: 42, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 8, eval_rewards: 47, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 46, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 9, eval_rewards: 42, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 9, eval_rewards: 48, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 9, eval_rewards: 49, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 8, eval_rewards: 46, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 48, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 9, eval_rewards: 47, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 49, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 47, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 49, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 49, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 9, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 48, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 46, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 9, eval_rewards: 45, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 46, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 49, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 48, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 9, eval_rewards: 49, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 46, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 47, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 48, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 49, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 49, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 49, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 49, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 49, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 47, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 49, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 3, eval_rewards: 20, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 26, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 18, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 3, eval_rewards: 19, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 3, eval_rewards: 27, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 3, eval_rewards: 25, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 4, eval_rewards: 27, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 6, eval_rewards: 25, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 4, eval_rewards: 20, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 7, eval_rewards: 21, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 23, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 5, eval_rewards: 25, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 4, eval_rewards: 23, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 4, eval_rewards: 21, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 3, eval_rewards: 23, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 5, eval_rewards: 17, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 5, eval_rewards: 23, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 6, eval_rewards: 14, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 2, eval_rewards: 17, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 1, eval_rewards: 17, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 2, eval_rewards: 23, eps:0.7899999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 220, train mean_rewards: 3, eval_rewards: 12, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 1, eval_rewards: 15, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 6, eval_rewards: 18, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 3, eval_rewards: 20, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 4, eval_rewards: 22, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 5, eval_rewards: 34, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 6, eval_rewards: 37, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 7, eval_rewards: 32, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 8, eval_rewards: 33, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 8, eval_rewards: 44, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 40, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 8, eval_rewards: 46, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 7, eval_rewards: 45, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 46, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 9, eval_rewards: 42, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 9, eval_rewards: 45, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 6, eval_rewards: 43, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 47, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 47, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 8, eval_rewards: 45, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 46, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 8, eval_rewards: 45, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 9, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 8, eval_rewards: 47, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 49, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 47, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 46, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 45, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 49, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 48, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 48, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 49, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 9, eval_rewards: 48, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 48, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 47, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 9, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 9, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 48, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 49, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 49, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 9, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 49, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 5, eval_rewards: 22, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 19, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 1, eval_rewards: 18, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 20, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 17, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 20, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 3, eval_rewards: 20, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 5, eval_rewards: 24, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 3, eval_rewards: 31, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 5, eval_rewards: 21, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 2, eval_rewards: 27, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 5, eval_rewards: 16, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 3, eval_rewards: 19, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 3, eval_rewards: 13, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 6, eval_rewards: 21, eps:0.8499999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 160, train mean_rewards: 4, eval_rewards: 17, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 3, eval_rewards: 14, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 6, eval_rewards: 17, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 0, eval_rewards: 17, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 4, eval_rewards: 7, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 2, eval_rewards: 12, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 4, eval_rewards: 15, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 2, eval_rewards: 8, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 5, eval_rewards: 18, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 3, eval_rewards: 10, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 3, eval_rewards: 4, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 3, eval_rewards: 20, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 1, eval_rewards: 11, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 2, eval_rewards: 10, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 2, eval_rewards: 18, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 3, eval_rewards: 12, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 1, eval_rewards: 11, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 5, eval_rewards: 12, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 1, eval_rewards: 20, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 2, eval_rewards: 10, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 1, eval_rewards: 9, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 3, eval_rewards: 4, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 1, eval_rewards: 16, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 4, eval_rewards: 15, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 6, eval_rewards: 17, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 3, eval_rewards: 21, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 5, eval_rewards: 30, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 7, eval_rewards: 39, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 7, eval_rewards: 42, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 7, eval_rewards: 34, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 39, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 9, eval_rewards: 43, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 46, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 46, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 9, eval_rewards: 41, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 7, eval_rewards: 41, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 44, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 9, eval_rewards: 47, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 45, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 9, eval_rewards: 47, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 9, eval_rewards: 44, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 42, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 46, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 47, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 46, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 44, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 48, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 9, eval_rewards: 43, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 9, eval_rewards: 48, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 9, eval_rewards: 47, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 48, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 9, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 49, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 9, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 9, eval_rewards: 49, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 48, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 49, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 9, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 9, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 48, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 49, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 49, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 49, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 4, eval_rewards: 17, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 19, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 23, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 22, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 25, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 21, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 26, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 23, eps:0.9099999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 100, train mean_rewards: 3, eval_rewards: 17, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 5, eval_rewards: 19, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 4, eval_rewards: 23, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 6, eval_rewards: 22, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 1, eval_rewards: 22, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 4, eval_rewards: 18, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 2, eval_rewards: 17, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 5, eval_rewards: 20, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 3, eval_rewards: 19, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 5, eval_rewards: 14, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 5, eval_rewards: 17, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 6, eval_rewards: 23, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 5, eval_rewards: 28, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 6, eval_rewards: 28, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 6, eval_rewards: 34, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 6, eval_rewards: 26, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 6, eval_rewards: 36, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 25, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 7, eval_rewards: 35, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 6, eval_rewards: 38, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 5, eval_rewards: 41, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 7, eval_rewards: 39, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 7, eval_rewards: 33, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 7, eval_rewards: 42, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 6, eval_rewards: 39, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 41, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 8, eval_rewards: 47, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 47, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 9, eval_rewards: 44, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 9, eval_rewards: 46, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 46, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 45, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 47, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 45, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 9, eval_rewards: 49, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 9, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 9, eval_rewards: 48, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 9, eval_rewards: 45, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 49, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 9, eval_rewards: 47, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 49, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 46, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 47, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 48, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 47, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 48, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 48, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 9, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 48, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 49, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 48, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 49, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 9, eval_rewards: 49, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 49, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 9, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "count matrix: 0.0\n",
      "training episodes: 10, train mean_rewards: 2, eval_rewards: 29, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 23, eps:0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 30, train mean_rewards: 4, eval_rewards: 28, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 6, eval_rewards: 25, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 4, eval_rewards: 26, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 16, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 24, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 24, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 6, eval_rewards: 23, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 25, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 24, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 4, eval_rewards: 27, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 5, eval_rewards: 34, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 29, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 6, eval_rewards: 31, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 7, eval_rewards: 33, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 10, eval_rewards: 36, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 7, eval_rewards: 40, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 8, eval_rewards: 40, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 8, eval_rewards: 34, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 5, eval_rewards: 38, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 8, eval_rewards: 43, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 40, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 37, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 9, eval_rewards: 45, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 39, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 47, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 43, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 44, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 9, eval_rewards: 47, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 44, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 48, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 42, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 46, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 44, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 48, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 48, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 46, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 47, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 47, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 9, eval_rewards: 48, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 48, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 9, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 48, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 49, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 9, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 9, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 49, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "mode: reward shift -0.02\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 2, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 26, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 29, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 5, eval_rewards: 25, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 5, eval_rewards: 27, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 7, eval_rewards: 31, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 7, eval_rewards: 31, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 42, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 7, eval_rewards: 34, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 41, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 36, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 37, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 47, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 9, eval_rewards: 40, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 6, eval_rewards: 39, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 43, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 7, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 47, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 10, eval_rewards: 41, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 8, eval_rewards: 47, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 8, eval_rewards: 45, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 9, eval_rewards: 45, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 49, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 48, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 50, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 48, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 49, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 49, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 4, eval_rewards: 20, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 21, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 29, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 6, eval_rewards: 33, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 23, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 33, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 30, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 8, eval_rewards: 33, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 7, eval_rewards: 33, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 35, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 39, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 9, eval_rewards: 41, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 10, eval_rewards: 40, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 40, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 9, eval_rewards: 45, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 10, eval_rewards: 41, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 42, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 46, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 48, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 43, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 47, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 46, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 48, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 8, eval_rewards: 48, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 9, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 49, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 49, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 47, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 3, eval_rewards: 18, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 27, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 2, eval_rewards: 28, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 6, eval_rewards: 32, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 7, eval_rewards: 29, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 29, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 8, eval_rewards: 29, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 8, eval_rewards: 26, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 36, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 7, eval_rewards: 38, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 30, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 32, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 7, eval_rewards: 42, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 40, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 42, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 9, eval_rewards: 44, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 8, eval_rewards: 43, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 9, eval_rewards: 48, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 45, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 48, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 47, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 50, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 9, eval_rewards: 48, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 48, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 9, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 2, eval_rewards: 24, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 23, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 18, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 3, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 5, eval_rewards: 21, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 7, eval_rewards: 27, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 8, eval_rewards: 33, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 4, eval_rewards: 33, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 10, eval_rewards: 37, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 5, eval_rewards: 38, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 35, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 41, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 4, eval_rewards: 38, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 10, eval_rewards: 42, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 9, eval_rewards: 42, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 42, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 7, eval_rewards: 43, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 42, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 6, eval_rewards: 43, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 9, eval_rewards: 47, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 45, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 48, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 48, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 50, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 50, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 47, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 49, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 21, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 30, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 5, eval_rewards: 24, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 30, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 7, eval_rewards: 26, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 7, eval_rewards: 33, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 5, eval_rewards: 29, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 10, eval_rewards: 34, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 32, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 39, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 37, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 9, eval_rewards: 38, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 38, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 8, eval_rewards: 46, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 7, eval_rewards: 43, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 9, eval_rewards: 38, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 10, eval_rewards: 42, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 8, eval_rewards: 45, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 43, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 46, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 49, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 48, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 48, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 49, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 47, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 47, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 49, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 49, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 49, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 20, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 4, eval_rewards: 25, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 4, eval_rewards: 31, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 29, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 9, eval_rewards: 27, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 5, eval_rewards: 30, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 40, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 5, eval_rewards: 34, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 6, eval_rewards: 39, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 9, eval_rewards: 37, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 7, eval_rewards: 36, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 8, eval_rewards: 42, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 9, eval_rewards: 39, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 7, eval_rewards: 34, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 10, eval_rewards: 40, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 8, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 46, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 7, eval_rewards: 48, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 45, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 46, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 46, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 46, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 47, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 7, eval_rewards: 48, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 48, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 49, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 49, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 49, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 25, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 28, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 31, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 7, eval_rewards: 26, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 26, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 7, eval_rewards: 29, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 8, eval_rewards: 39, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 2, eval_rewards: 31, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 9, eval_rewards: 32, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 7, eval_rewards: 32, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 6, eval_rewards: 42, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 38, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 9, eval_rewards: 42, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 6, eval_rewards: 42, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 10, eval_rewards: 40, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 7, eval_rewards: 43, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 7, eval_rewards: 41, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 43, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 46, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 9, eval_rewards: 45, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 43, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 8, eval_rewards: 44, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 48, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 48, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 49, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 47, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 49, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 50, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 49, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 49, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 49, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 49, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 4, eval_rewards: 22, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 28, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 2, eval_rewards: 22, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 5, eval_rewards: 28, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 22, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 4, eval_rewards: 30, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 28, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 35, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 38, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 37, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 8, eval_rewards: 37, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 8, eval_rewards: 39, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 9, eval_rewards: 36, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 8, eval_rewards: 44, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 8, eval_rewards: 41, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 9, eval_rewards: 38, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 8, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 9, eval_rewards: 45, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 8, eval_rewards: 39, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 10, eval_rewards: 41, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 10, eval_rewards: 47, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 48, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 48, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 47, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 9, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 47, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 50, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 50, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 10, eval_rewards: 49, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 50, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 49, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 49, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 4, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 4, eval_rewards: 19, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 7, eval_rewards: 23, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 3, eval_rewards: 29, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 6, eval_rewards: 27, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 10, eval_rewards: 30, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 6, eval_rewards: 31, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 32, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 8, eval_rewards: 33, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 7, eval_rewards: 37, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 7, eval_rewards: 34, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 9, eval_rewards: 38, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 7, eval_rewards: 40, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 8, eval_rewards: 40, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 7, eval_rewards: 41, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 8, eval_rewards: 43, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 8, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 10, eval_rewards: 46, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 42, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 7, eval_rewards: 45, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 48, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 10, eval_rewards: 46, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 8, eval_rewards: 45, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 50, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 45, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 10, eval_rewards: 47, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 50, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 8, eval_rewards: 49, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 49, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 50, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 50, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 49, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "reward shift -0.02\n",
      "training episodes: 10, train mean_rewards: 6, eval_rewards: 23, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 5, eval_rewards: 27, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 6, eval_rewards: 20, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 6, eval_rewards: 29, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 7, eval_rewards: 28, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 5, eval_rewards: 34, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 8, eval_rewards: 26, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 7, eval_rewards: 30, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 7, eval_rewards: 38, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 8, eval_rewards: 38, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 7, eval_rewards: 40, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 6, eval_rewards: 37, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 7, eval_rewards: 37, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 8, eval_rewards: 39, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 10, eval_rewards: 42, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 4, eval_rewards: 38, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 9, eval_rewards: 44, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 8, eval_rewards: 49, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 9, eval_rewards: 43, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 9, eval_rewards: 41, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 9, eval_rewards: 47, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 50, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 10, eval_rewards: 47, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 10, eval_rewards: 47, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 10, eval_rewards: 49, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 9, eval_rewards: 46, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 10, eval_rewards: 49, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 50, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 50, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 48, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 50, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 49, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 10, eval_rewards: 49, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 50, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 50, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 50, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 50, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 49, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "GOAL = 5\n",
    "from asyncore import readwrite\n",
    "from os import environ\n",
    "from unittest.util import _count_diff_all_purpose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "class GridEnv():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.state = np.array([0,0])\n",
    "        self.action = np.array([0,0])\n",
    "        self.goal = np.array([GOAL-1, GOAL-1])\n",
    "        self.horizon = 100\n",
    "        self.steps = 0\n",
    "        self.action_dict = {\n",
    "            0: np.array([1,0]),\n",
    "            1: np.array([0,1]),\n",
    "            2: np.array([-1,0]),\n",
    "            3: np.array([0,-1]),\n",
    "        }\n",
    "\n",
    "    def _process_action(self, action):\n",
    "        assert 0 <= action <= 3, 'Action error {}!'.format(action)\n",
    "        if type(action) != int:\n",
    "            action = int(action)\n",
    "        return self.action_dict[action]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0])\n",
    "        #self.goal = np.array([self.size-1, self.size-1])\n",
    "        self.steps = 0\n",
    "        return self.state.copy()\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = self._process_action(action)\n",
    "        self.state += action\n",
    "        self.state = np.clip(self.state, 0, self.size-1)\n",
    "        if np.all(self.state == self.goal):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.steps += 1\n",
    "        done = False\n",
    "        if self.steps >= self.horizon or reward == 1:\n",
    "            done = True \n",
    "        info = {}\n",
    "        return self.state.copy(), reward, done, info \n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, num_action=4, eps_greedy=True, mode='', gamma=0.99):\n",
    "        self.state_size = state_size\n",
    "        self.num_action = num_action\n",
    "        self.Q_values = np.zeros((state_size, state_size, num_action))  \n",
    "        self.eps_greedy = eps_greedy\n",
    "        self.eps_init = 1\n",
    "        self.eps = self.eps_init\n",
    "        self.eps_decay = 0.001  \n",
    "        self.learning_rate = 1\n",
    "        self.gamma = gamma\n",
    "        # mode\n",
    "        self.mode = mode\n",
    "        if mode == 'opt_init':\n",
    "            self.Q_values += 1\n",
    "            print('Q_value: {}'.format(self.Q_values.mean()))\n",
    "        elif mode == 'count':\n",
    "            # count\n",
    "            self.count_matrix = np.zeros((state_size, state_size))\n",
    "            print('count matrix: {}'.format(self.count_matrix.mean()))\n",
    "        elif mode.startswith('reward shift'):\n",
    "            self.reward_shift = float(mode.replace('reward shift ', ''))\n",
    "            print('reward shift {}'.format(self.reward_shift))\n",
    "        else:\n",
    "            print('no mode')\n",
    "\n",
    "    \n",
    "    def _decay_eps(self):\n",
    "        self.eps = max(0, self.eps - self.eps_decay)\n",
    "    \n",
    "    def act(self, state, random=False):\n",
    "        if self.mode == 'count':\n",
    "            self.count_matrix[state[0], state[1]] += 1\n",
    "\n",
    "        if random or (self.eps_greedy and np.random.random() < self.eps):\n",
    "            return np.random.randint(self.num_action)\n",
    "        argmax_action = np.argmax(self.Q_values[state[0], state[1]])\n",
    "        return argmax_action\n",
    "\n",
    "    def update_Q(self, transition):\n",
    "        state, action, next_state, reward, done = transition\n",
    "        argmax_action = np.argmax(self.Q_values[next_state[0], next_state[1]])\n",
    "\n",
    "        if self.mode.startswith('reward shift'):\n",
    "            reward  += self.reward_shift\n",
    "        elif self.mode == 'count':\n",
    "            reward += 1 / (self.count_matrix[state[0], state[1]] + 1) * 0.1\n",
    "\n",
    "        self.Q_values[state[0], state[1]][action] += self.learning_rate * (reward + \n",
    "                        self.gamma * self.Q_values[next_state[0], next_state[1]][argmax_action] - self.Q_values[state[0], state[1]][action])\n",
    "\n",
    "def rollout(agent, env, episode=10, eval=False):\n",
    "    reward_list = []\n",
    "    for _ in range(episode):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        rewards = 0\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            if not eval:\n",
    "                agent.update_Q([state, action, next_state, reward, done])\n",
    "            rewards += reward\n",
    "            state = next_state\n",
    "        reward_list.append(rewards)\n",
    "        if not eval:\n",
    "            agent._decay_eps()\n",
    "    return np.sum(reward_list)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_curves = True # if false, plot heatmap\n",
    "    size = 20  # set the map size\n",
    "    print_every = 10\n",
    "\n",
    "    if plot_curves:\n",
    "        num_seed = 10\n",
    "        num_episode = 1000 \n",
    "        eval_episodes = 50  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02'] # 'opt_init', 'reward shift -0.1'\n",
    "    else:\n",
    "        num_seed = 1\n",
    "        num_episode = 1500\n",
    "        eval_episodes = 10  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02', 'reward shift -0.1'] # 'opt_init', \n",
    "    \n",
    "    result_all_list = []\n",
    "    for j, mode in enumerate(mode_list):\n",
    "        print('mode: {}'.format(mode))\n",
    "        result_seed = []\n",
    "        for seed in range(num_seed):\n",
    "            result = []\n",
    "            env = GridEnv(size=size)\n",
    "            agent = Agent(state_size=size, mode=mode)\n",
    "            for i in range(num_episode // print_every):\n",
    "                train_rewards = rollout(agent, env, episode=print_every)\n",
    "                eval_rewards = rollout(agent, env, eval=True, episode=eval_episodes)\n",
    "                print('training episodes: {}, train mean_rewards: {}, eval_rewards: {}, eps:{}'.format((i+1)* print_every,\n",
    "                                    train_rewards, eval_rewards, agent.eps))\n",
    "                result.append(eval_rewards)\n",
    "            result_seed.append(result)\n",
    "        \n",
    "        result_all_list.append(result_seed)\n",
    "\n",
    "        # plot heatmap\n",
    "        if not plot_curves:\n",
    "            plt.subplot(1,len(mode_list), j+1) \n",
    "            # normalize Q values\n",
    "            Q_values = agent.Q_values.max(axis=2).copy()\n",
    "            Q_max, Q_min = Q_values.max(), Q_values.min()\n",
    "            if Q_max == Q_min:\n",
    "                Q_values_norm = np.zeros(Q_values.shape)\n",
    "            else:\n",
    "                Q_values_norm = (Q_values - Q_min) / (Q_max - Q_min)\n",
    "            sns.heatmap(data=Q_values_norm, square=True, vmin=0, vmax=1) \n",
    "            plt.title(mode)\n",
    "    \n",
    "    if not plot_curves:\n",
    "        plt.show()\n",
    "    else:\n",
    "        x_axis = (np.arange(num_episode // print_every) + 1) * print_every\n",
    "        for i, mode in enumerate(mode_list):\n",
    "            if type(result_all_list[i][0]) == list:\n",
    "                array = np.array(result_all_list[i])\n",
    "                y_mean = array.mean(axis=0)\n",
    "                y_std = array.std(axis=0)\n",
    "                plt.plot(x_axis, y_mean, label=mode)\n",
    "                plt.fill_between(x_axis, y_mean - y_std, y_mean + y_std, alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(x_axis, result_all_list[i], label=mode)\n",
    "        plt.legend()\n",
    "        plt.title(r'Exploration in {} $\\times$ {} Grid World'.format(size, size))\n",
    "        plt.ylabel('Evaluation Returns')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.show()\n",
    "\n",
    "        # save\n",
    "        np.save('grid_return_{}.npy'.format(GOAL), np.array(result_all_list))\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58271ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: $\\epsilon-greedy$\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 4, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 1, eval_rewards: 3, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 4, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 1, eval_rewards: 5, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 1, eval_rewards: 1, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 2, eval_rewards: 4, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 1, eval_rewards: 4, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 4, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 1, eval_rewards: 8, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 3, eval_rewards: 14, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 3, eval_rewards: 9, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 1, eval_rewards: 14, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 2, eval_rewards: 17, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 1, eval_rewards: 15, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 5, eval_rewards: 21, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 1, eval_rewards: 24, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 4, eval_rewards: 20, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 5, eval_rewards: 25, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 4, eval_rewards: 26, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 5, eval_rewards: 29, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 7, eval_rewards: 21, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 6, eval_rewards: 30, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 6, eval_rewards: 30, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 7, eval_rewards: 28, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 7, eval_rewards: 36, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 5, eval_rewards: 36, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 8, eval_rewards: 35, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 10, eval_rewards: 37, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 8, eval_rewards: 40, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 7, eval_rewards: 44, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 8, eval_rewards: 46, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 8, eval_rewards: 44, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 39, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 48, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 10, eval_rewards: 45, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 46, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 47, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 48, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 49, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 49, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 9, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 48, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 49, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 48, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 4, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 4, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 3, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 4, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 1, eval_rewards: 1, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 2, eval_rewards: 4, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 1, eval_rewards: 2, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 3, eval_rewards: 3, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 2, eval_rewards: 7, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 1, eval_rewards: 9, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 1, eval_rewards: 9, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 2, eval_rewards: 13, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 1, eval_rewards: 15, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 2, eval_rewards: 15, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 3, eval_rewards: 16, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 2, eval_rewards: 19, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 6, eval_rewards: 16, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 1, eval_rewards: 23, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 7, eval_rewards: 26, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 4, eval_rewards: 20, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 5, eval_rewards: 29, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 5, eval_rewards: 27, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 5, eval_rewards: 35, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 8, eval_rewards: 28, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 8, eval_rewards: 35, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 7, eval_rewards: 39, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 7, eval_rewards: 40, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 7, eval_rewards: 41, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 8, eval_rewards: 41, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 8, eval_rewards: 44, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 7, eval_rewards: 41, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 44, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 45, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 46, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 47, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 9, eval_rewards: 47, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 9, eval_rewards: 47, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 48, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 9, eval_rewards: 47, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 48, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 9, eval_rewards: 49, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 47, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 49, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 9, eval_rewards: 48, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 49, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 49, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 9, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 49, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 5, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 7, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 4, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 1, eval_rewards: 3, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 3, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 3, eval_rewards: 6, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 2, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 1, eval_rewards: 3, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 1, eval_rewards: 2, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 0, eval_rewards: 5, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 3, eval_rewards: 12, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 0, eval_rewards: 3, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 2, eval_rewards: 14, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 2, eval_rewards: 13, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 2, eval_rewards: 17, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 4, eval_rewards: 14, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 2, eval_rewards: 21, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 1, eval_rewards: 24, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 5, eval_rewards: 28, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 4, eval_rewards: 27, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 2, eval_rewards: 30, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 6, eval_rewards: 28, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 6, eval_rewards: 37, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 7, eval_rewards: 34, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 6, eval_rewards: 35, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 8, eval_rewards: 43, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 8, eval_rewards: 36, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 9, eval_rewards: 36, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 10, eval_rewards: 41, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 9, eval_rewards: 43, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 9, eval_rewards: 48, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 44, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 46, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 9, eval_rewards: 44, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 45, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 9, eval_rewards: 44, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 49, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 49, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 9, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 50, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 9, eval_rewards: 48, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 49, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 9, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 49, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 49, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 1, eval_rewards: 6, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 5, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 1, eval_rewards: 4, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 1, eval_rewards: 3, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 1, eval_rewards: 3, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 1, eval_rewards: 3, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 2, eval_rewards: 9, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 1, eval_rewards: 8, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 1, eval_rewards: 7, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 3, eval_rewards: 8, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 2, eval_rewards: 8, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 1, eval_rewards: 8, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 2, eval_rewards: 15, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 2, eval_rewards: 17, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 4, eval_rewards: 18, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 3, eval_rewards: 15, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 1, eval_rewards: 18, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 2, eval_rewards: 23, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 3, eval_rewards: 21, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 4, eval_rewards: 30, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 6, eval_rewards: 23, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 9, eval_rewards: 27, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 6, eval_rewards: 35, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 9, eval_rewards: 29, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 7, eval_rewards: 35, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 5, eval_rewards: 39, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 7, eval_rewards: 42, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 8, eval_rewards: 40, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 7, eval_rewards: 42, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 7, eval_rewards: 41, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 7, eval_rewards: 45, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 10, eval_rewards: 46, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 8, eval_rewards: 46, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 45, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 47, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 44, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 9, eval_rewards: 48, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 10, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 9, eval_rewards: 49, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 9, eval_rewards: 49, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 9, eval_rewards: 48, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 50, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 50, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 49, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 48, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 49, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 49, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 3, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 1, eval_rewards: 4, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 1, eval_rewards: 5, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 1, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 0, eval_rewards: 5, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 0, eval_rewards: 6, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 5, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 1, eval_rewards: 6, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 1, eval_rewards: 9, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 3, eval_rewards: 8, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 2, eval_rewards: 9, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 3, eval_rewards: 5, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 2, eval_rewards: 11, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 3, eval_rewards: 16, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 0, eval_rewards: 18, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 4, eval_rewards: 17, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 4, eval_rewards: 18, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 6, eval_rewards: 21, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 4, eval_rewards: 26, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 5, eval_rewards: 31, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 5, eval_rewards: 27, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 4, eval_rewards: 29, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 8, eval_rewards: 38, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 5, eval_rewards: 31, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 7, eval_rewards: 41, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 6, eval_rewards: 36, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 8, eval_rewards: 37, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 7, eval_rewards: 46, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 7, eval_rewards: 41, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 10, eval_rewards: 44, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 7, eval_rewards: 46, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 8, eval_rewards: 47, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 8, eval_rewards: 47, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 10, eval_rewards: 47, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 9, eval_rewards: 47, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 9, eval_rewards: 47, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 10, eval_rewards: 46, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 9, eval_rewards: 50, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 49, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 48, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 9, eval_rewards: 49, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 10, eval_rewards: 50, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 49, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 48, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 49, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 50, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 9, eval_rewards: 50, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 50, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 49, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n",
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 5, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 0, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 5, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 0, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 2, eval_rewards: 5, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 1, eval_rewards: 3, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 0, eval_rewards: 2, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 1, eval_rewards: 9, eps:0.9199999999999999\n",
      "training episodes: 90, train mean_rewards: 1, eval_rewards: 7, eps:0.9099999999999999\n",
      "training episodes: 100, train mean_rewards: 1, eval_rewards: 3, eps:0.8999999999999999\n",
      "training episodes: 110, train mean_rewards: 1, eval_rewards: 8, eps:0.8899999999999999\n",
      "training episodes: 120, train mean_rewards: 3, eval_rewards: 11, eps:0.8799999999999999\n",
      "training episodes: 130, train mean_rewards: 2, eval_rewards: 7, eps:0.8699999999999999\n",
      "training episodes: 140, train mean_rewards: 7, eval_rewards: 11, eps:0.8599999999999999\n",
      "training episodes: 150, train mean_rewards: 4, eval_rewards: 18, eps:0.8499999999999999\n",
      "training episodes: 160, train mean_rewards: 3, eval_rewards: 15, eps:0.8399999999999999\n",
      "training episodes: 170, train mean_rewards: 2, eval_rewards: 16, eps:0.8299999999999998\n",
      "training episodes: 180, train mean_rewards: 3, eval_rewards: 19, eps:0.8199999999999998\n",
      "training episodes: 190, train mean_rewards: 2, eval_rewards: 26, eps:0.8099999999999998\n",
      "training episodes: 200, train mean_rewards: 5, eval_rewards: 24, eps:0.7999999999999998\n",
      "training episodes: 210, train mean_rewards: 8, eval_rewards: 29, eps:0.7899999999999998\n",
      "training episodes: 220, train mean_rewards: 5, eval_rewards: 31, eps:0.7799999999999998\n",
      "training episodes: 230, train mean_rewards: 5, eval_rewards: 29, eps:0.7699999999999998\n",
      "training episodes: 240, train mean_rewards: 7, eval_rewards: 35, eps:0.7599999999999998\n",
      "training episodes: 250, train mean_rewards: 5, eval_rewards: 33, eps:0.7499999999999998\n",
      "training episodes: 260, train mean_rewards: 8, eval_rewards: 35, eps:0.7399999999999998\n",
      "training episodes: 270, train mean_rewards: 8, eval_rewards: 34, eps:0.7299999999999998\n",
      "training episodes: 280, train mean_rewards: 8, eval_rewards: 38, eps:0.7199999999999998\n",
      "training episodes: 290, train mean_rewards: 9, eval_rewards: 43, eps:0.7099999999999997\n",
      "training episodes: 300, train mean_rewards: 8, eval_rewards: 36, eps:0.6999999999999997\n",
      "training episodes: 310, train mean_rewards: 8, eval_rewards: 43, eps:0.6899999999999997\n",
      "training episodes: 320, train mean_rewards: 9, eval_rewards: 42, eps:0.6799999999999997\n",
      "training episodes: 330, train mean_rewards: 9, eval_rewards: 43, eps:0.6699999999999997\n",
      "training episodes: 340, train mean_rewards: 8, eval_rewards: 44, eps:0.6599999999999997\n",
      "training episodes: 350, train mean_rewards: 8, eval_rewards: 46, eps:0.6499999999999997\n",
      "training episodes: 360, train mean_rewards: 10, eval_rewards: 43, eps:0.6399999999999997\n",
      "training episodes: 370, train mean_rewards: 9, eval_rewards: 43, eps:0.6299999999999997\n",
      "training episodes: 380, train mean_rewards: 9, eval_rewards: 48, eps:0.6199999999999997\n",
      "training episodes: 390, train mean_rewards: 10, eval_rewards: 50, eps:0.6099999999999997\n",
      "training episodes: 400, train mean_rewards: 10, eval_rewards: 48, eps:0.5999999999999996\n",
      "training episodes: 410, train mean_rewards: 10, eval_rewards: 50, eps:0.5899999999999996\n",
      "training episodes: 420, train mean_rewards: 9, eval_rewards: 48, eps:0.5799999999999996\n",
      "training episodes: 430, train mean_rewards: 10, eval_rewards: 48, eps:0.5699999999999996\n",
      "training episodes: 440, train mean_rewards: 10, eval_rewards: 49, eps:0.5599999999999996\n",
      "training episodes: 450, train mean_rewards: 10, eval_rewards: 50, eps:0.5499999999999996\n",
      "training episodes: 460, train mean_rewards: 10, eval_rewards: 50, eps:0.5399999999999996\n",
      "training episodes: 470, train mean_rewards: 10, eval_rewards: 50, eps:0.5299999999999996\n",
      "training episodes: 480, train mean_rewards: 10, eval_rewards: 50, eps:0.5199999999999996\n",
      "training episodes: 490, train mean_rewards: 10, eval_rewards: 50, eps:0.5099999999999996\n",
      "training episodes: 500, train mean_rewards: 10, eval_rewards: 49, eps:0.49999999999999956\n",
      "training episodes: 510, train mean_rewards: 10, eval_rewards: 50, eps:0.48999999999999955\n",
      "training episodes: 520, train mean_rewards: 10, eval_rewards: 50, eps:0.47999999999999954\n",
      "training episodes: 530, train mean_rewards: 10, eval_rewards: 49, eps:0.46999999999999953\n",
      "training episodes: 540, train mean_rewards: 10, eval_rewards: 50, eps:0.4599999999999995\n",
      "training episodes: 550, train mean_rewards: 10, eval_rewards: 50, eps:0.4499999999999995\n",
      "training episodes: 560, train mean_rewards: 10, eval_rewards: 50, eps:0.4399999999999995\n",
      "training episodes: 570, train mean_rewards: 10, eval_rewards: 50, eps:0.4299999999999995\n",
      "training episodes: 580, train mean_rewards: 10, eval_rewards: 49, eps:0.4199999999999995\n",
      "training episodes: 590, train mean_rewards: 10, eval_rewards: 50, eps:0.4099999999999995\n",
      "training episodes: 600, train mean_rewards: 10, eval_rewards: 50, eps:0.39999999999999947\n",
      "training episodes: 610, train mean_rewards: 10, eval_rewards: 50, eps:0.38999999999999946\n",
      "training episodes: 620, train mean_rewards: 10, eval_rewards: 50, eps:0.37999999999999945\n",
      "training episodes: 630, train mean_rewards: 10, eval_rewards: 50, eps:0.36999999999999944\n",
      "training episodes: 640, train mean_rewards: 10, eval_rewards: 50, eps:0.35999999999999943\n",
      "training episodes: 650, train mean_rewards: 10, eval_rewards: 50, eps:0.3499999999999994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training episodes: 660, train mean_rewards: 10, eval_rewards: 50, eps:0.3399999999999994\n",
      "training episodes: 670, train mean_rewards: 10, eval_rewards: 50, eps:0.3299999999999994\n",
      "training episodes: 680, train mean_rewards: 10, eval_rewards: 50, eps:0.3199999999999994\n",
      "training episodes: 690, train mean_rewards: 10, eval_rewards: 50, eps:0.3099999999999994\n",
      "training episodes: 700, train mean_rewards: 10, eval_rewards: 50, eps:0.2999999999999994\n",
      "training episodes: 710, train mean_rewards: 10, eval_rewards: 50, eps:0.28999999999999937\n",
      "training episodes: 720, train mean_rewards: 10, eval_rewards: 50, eps:0.27999999999999936\n",
      "training episodes: 730, train mean_rewards: 10, eval_rewards: 50, eps:0.26999999999999935\n",
      "training episodes: 740, train mean_rewards: 10, eval_rewards: 50, eps:0.25999999999999934\n",
      "training episodes: 750, train mean_rewards: 10, eval_rewards: 50, eps:0.24999999999999933\n",
      "training episodes: 760, train mean_rewards: 10, eval_rewards: 50, eps:0.23999999999999932\n",
      "training episodes: 770, train mean_rewards: 10, eval_rewards: 50, eps:0.22999999999999932\n",
      "training episodes: 780, train mean_rewards: 10, eval_rewards: 50, eps:0.2199999999999993\n",
      "training episodes: 790, train mean_rewards: 10, eval_rewards: 50, eps:0.2099999999999993\n",
      "training episodes: 800, train mean_rewards: 10, eval_rewards: 50, eps:0.1999999999999993\n",
      "training episodes: 810, train mean_rewards: 10, eval_rewards: 50, eps:0.18999999999999928\n",
      "training episodes: 820, train mean_rewards: 10, eval_rewards: 50, eps:0.17999999999999927\n",
      "training episodes: 830, train mean_rewards: 10, eval_rewards: 50, eps:0.16999999999999926\n",
      "training episodes: 840, train mean_rewards: 10, eval_rewards: 50, eps:0.15999999999999925\n",
      "training episodes: 850, train mean_rewards: 10, eval_rewards: 50, eps:0.14999999999999925\n",
      "training episodes: 860, train mean_rewards: 10, eval_rewards: 50, eps:0.13999999999999924\n",
      "training episodes: 870, train mean_rewards: 10, eval_rewards: 50, eps:0.12999999999999923\n",
      "training episodes: 880, train mean_rewards: 10, eval_rewards: 50, eps:0.11999999999999922\n",
      "training episodes: 890, train mean_rewards: 10, eval_rewards: 50, eps:0.10999999999999921\n",
      "training episodes: 900, train mean_rewards: 10, eval_rewards: 50, eps:0.0999999999999992\n",
      "training episodes: 910, train mean_rewards: 10, eval_rewards: 50, eps:0.08999999999999919\n",
      "training episodes: 920, train mean_rewards: 10, eval_rewards: 50, eps:0.07999999999999918\n",
      "training episodes: 930, train mean_rewards: 10, eval_rewards: 50, eps:0.06999999999999917\n",
      "training episodes: 940, train mean_rewards: 10, eval_rewards: 50, eps:0.059999999999999165\n",
      "training episodes: 950, train mean_rewards: 10, eval_rewards: 50, eps:0.049999999999999156\n",
      "training episodes: 960, train mean_rewards: 10, eval_rewards: 50, eps:0.03999999999999915\n",
      "training episodes: 970, train mean_rewards: 10, eval_rewards: 50, eps:0.02999999999999914\n",
      "training episodes: 980, train mean_rewards: 10, eval_rewards: 50, eps:0.01999999999999913\n",
      "training episodes: 990, train mean_rewards: 10, eval_rewards: 50, eps:0.00999999999999912\n",
      "training episodes: 1000, train mean_rewards: 10, eval_rewards: 50, eps:0\n",
      "no mode\n",
      "training episodes: 10, train mean_rewards: 0, eval_rewards: 3, eps:0.99\n",
      "training episodes: 20, train mean_rewards: 0, eval_rewards: 3, eps:0.98\n",
      "training episodes: 30, train mean_rewards: 0, eval_rewards: 4, eps:0.97\n",
      "training episodes: 40, train mean_rewards: 0, eval_rewards: 8, eps:0.96\n",
      "training episodes: 50, train mean_rewards: 2, eval_rewards: 5, eps:0.95\n",
      "training episodes: 60, train mean_rewards: 1, eval_rewards: 4, eps:0.94\n",
      "training episodes: 70, train mean_rewards: 1, eval_rewards: 5, eps:0.9299999999999999\n",
      "training episodes: 80, train mean_rewards: 0, eval_rewards: 6, eps:0.9199999999999999\n"
     ]
    }
   ],
   "source": [
    "GOAL = 10\n",
    "from asyncore import readwrite\n",
    "from os import environ\n",
    "from unittest.util import _count_diff_all_purpose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "class GridEnv():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.state = np.array([0,0])\n",
    "        self.action = np.array([0,0])\n",
    "        self.goal = np.array([GOAL-1, GOAL-1])\n",
    "        self.horizon = 100\n",
    "        self.steps = 0\n",
    "        self.action_dict = {\n",
    "            0: np.array([1,0]),\n",
    "            1: np.array([0,1]),\n",
    "            2: np.array([-1,0]),\n",
    "            3: np.array([0,-1]),\n",
    "        }\n",
    "\n",
    "    def _process_action(self, action):\n",
    "        assert 0 <= action <= 3, 'Action error {}!'.format(action)\n",
    "        if type(action) != int:\n",
    "            action = int(action)\n",
    "        return self.action_dict[action]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0])\n",
    "        #self.goal = np.array([self.size-1, self.size-1])\n",
    "        self.steps = 0\n",
    "        return self.state.copy()\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = self._process_action(action)\n",
    "        self.state += action\n",
    "        self.state = np.clip(self.state, 0, self.size-1)\n",
    "        if np.all(self.state == self.goal):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.steps += 1\n",
    "        done = False\n",
    "        if self.steps >= self.horizon or reward == 1:\n",
    "            done = True \n",
    "        info = {}\n",
    "        return self.state.copy(), reward, done, info \n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, num_action=4, eps_greedy=True, mode='', gamma=0.99):\n",
    "        self.state_size = state_size\n",
    "        self.num_action = num_action\n",
    "        self.Q_values = np.zeros((state_size, state_size, num_action))  \n",
    "        self.eps_greedy = eps_greedy\n",
    "        self.eps_init = 1\n",
    "        self.eps = self.eps_init\n",
    "        self.eps_decay = 0.001  \n",
    "        self.learning_rate = 1\n",
    "        self.gamma = gamma\n",
    "        # mode\n",
    "        self.mode = mode\n",
    "        if mode == 'opt_init':\n",
    "            self.Q_values += 1\n",
    "            print('Q_value: {}'.format(self.Q_values.mean()))\n",
    "        elif mode == 'count':\n",
    "            # count\n",
    "            self.count_matrix = np.zeros((state_size, state_size))\n",
    "            print('count matrix: {}'.format(self.count_matrix.mean()))\n",
    "        elif mode.startswith('reward shift'):\n",
    "            self.reward_shift = float(mode.replace('reward shift ', ''))\n",
    "            print('reward shift {}'.format(self.reward_shift))\n",
    "        else:\n",
    "            print('no mode')\n",
    "\n",
    "    \n",
    "    def _decay_eps(self):\n",
    "        self.eps = max(0, self.eps - self.eps_decay)\n",
    "    \n",
    "    def act(self, state, random=False):\n",
    "        if self.mode == 'count':\n",
    "            self.count_matrix[state[0], state[1]] += 1\n",
    "\n",
    "        if random or (self.eps_greedy and np.random.random() < self.eps):\n",
    "            return np.random.randint(self.num_action)\n",
    "        argmax_action = np.argmax(self.Q_values[state[0], state[1]])\n",
    "        return argmax_action\n",
    "\n",
    "    def update_Q(self, transition):\n",
    "        state, action, next_state, reward, done = transition\n",
    "        argmax_action = np.argmax(self.Q_values[next_state[0], next_state[1]])\n",
    "\n",
    "        if self.mode.startswith('reward shift'):\n",
    "            reward  += self.reward_shift\n",
    "        elif self.mode == 'count':\n",
    "            reward += 1 / (self.count_matrix[state[0], state[1]] + 1) * 0.1\n",
    "\n",
    "        self.Q_values[state[0], state[1]][action] += self.learning_rate * (reward + \n",
    "                        self.gamma * self.Q_values[next_state[0], next_state[1]][argmax_action] - self.Q_values[state[0], state[1]][action])\n",
    "\n",
    "def rollout(agent, env, episode=10, eval=False):\n",
    "    reward_list = []\n",
    "    for _ in range(episode):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        rewards = 0\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            if not eval:\n",
    "                agent.update_Q([state, action, next_state, reward, done])\n",
    "            rewards += reward\n",
    "            state = next_state\n",
    "        reward_list.append(rewards)\n",
    "        if not eval:\n",
    "            agent._decay_eps()\n",
    "    return np.sum(reward_list)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_curves = True # if false, plot heatmap\n",
    "    size = 20  # set the map size\n",
    "    print_every = 10\n",
    "\n",
    "    if plot_curves:\n",
    "        num_seed = 10\n",
    "        num_episode = 1000 \n",
    "        eval_episodes = 50  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02'] # 'opt_init', 'reward shift -0.1'\n",
    "    else:\n",
    "        num_seed = 1\n",
    "        num_episode = 1500\n",
    "        eval_episodes = 10  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02', 'reward shift -0.1'] # 'opt_init', \n",
    "    \n",
    "    result_all_list = []\n",
    "    for j, mode in enumerate(mode_list):\n",
    "        print('mode: {}'.format(mode))\n",
    "        result_seed = []\n",
    "        for seed in range(num_seed):\n",
    "            result = []\n",
    "            env = GridEnv(size=size)\n",
    "            agent = Agent(state_size=size, mode=mode)\n",
    "            for i in range(num_episode // print_every):\n",
    "                train_rewards = rollout(agent, env, episode=print_every)\n",
    "                eval_rewards = rollout(agent, env, eval=True, episode=eval_episodes)\n",
    "                print('training episodes: {}, train mean_rewards: {}, eval_rewards: {}, eps:{}'.format((i+1)* print_every,\n",
    "                                    train_rewards, eval_rewards, agent.eps))\n",
    "                result.append(eval_rewards)\n",
    "            result_seed.append(result)\n",
    "        \n",
    "        result_all_list.append(result_seed)\n",
    "\n",
    "        # plot heatmap\n",
    "        if not plot_curves:\n",
    "            plt.subplot(1,len(mode_list), j+1) \n",
    "            # normalize Q values\n",
    "            Q_values = agent.Q_values.max(axis=2).copy()\n",
    "            Q_max, Q_min = Q_values.max(), Q_values.min()\n",
    "            if Q_max == Q_min:\n",
    "                Q_values_norm = np.zeros(Q_values.shape)\n",
    "            else:\n",
    "                Q_values_norm = (Q_values - Q_min) / (Q_max - Q_min)\n",
    "            sns.heatmap(data=Q_values_norm, square=True, vmin=0, vmax=1) \n",
    "            plt.title(mode)\n",
    "    \n",
    "    if not plot_curves:\n",
    "        plt.show()\n",
    "    else:\n",
    "        x_axis = (np.arange(num_episode // print_every) + 1) * print_every\n",
    "        for i, mode in enumerate(mode_list):\n",
    "            if type(result_all_list[i][0]) == list:\n",
    "                array = np.array(result_all_list[i])\n",
    "                y_mean = array.mean(axis=0)\n",
    "                y_std = array.std(axis=0)\n",
    "                plt.plot(x_axis, y_mean, label=mode)\n",
    "                plt.fill_between(x_axis, y_mean - y_std, y_mean + y_std, alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(x_axis, result_all_list[i], label=mode)\n",
    "        plt.legend()\n",
    "        plt.title(r'Exploration in {} $\\times$ {} Grid World'.format(size, size))\n",
    "        plt.ylabel('Evaluation Returns')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.show()\n",
    "\n",
    "        # save\n",
    "        np.save('grid_return_{}.npy'.format(GOAL), np.array(result_all_list))\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL = 15\n",
    "from asyncore import readwrite\n",
    "from os import environ\n",
    "from unittest.util import _count_diff_all_purpose\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "class GridEnv():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.state = np.array([0,0])\n",
    "        self.action = np.array([0,0])\n",
    "        self.goal = np.array([GOAL-1, GOAL-1])\n",
    "        self.horizon = 100\n",
    "        self.steps = 0\n",
    "        self.action_dict = {\n",
    "            0: np.array([1,0]),\n",
    "            1: np.array([0,1]),\n",
    "            2: np.array([-1,0]),\n",
    "            3: np.array([0,-1]),\n",
    "        }\n",
    "\n",
    "    def _process_action(self, action):\n",
    "        assert 0 <= action <= 3, 'Action error {}!'.format(action)\n",
    "        if type(action) != int:\n",
    "            action = int(action)\n",
    "        return self.action_dict[action]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = np.array([0,0])\n",
    "        #self.goal = np.array([self.size-1, self.size-1])\n",
    "        self.steps = 0\n",
    "        return self.state.copy()\n",
    "    \n",
    "    def step(self, action):\n",
    "        action = self._process_action(action)\n",
    "        self.state += action\n",
    "        self.state = np.clip(self.state, 0, self.size-1)\n",
    "        if np.all(self.state == self.goal):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.steps += 1\n",
    "        done = False\n",
    "        if self.steps >= self.horizon or reward == 1:\n",
    "            done = True \n",
    "        info = {}\n",
    "        return self.state.copy(), reward, done, info \n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, state_size, num_action=4, eps_greedy=True, mode='', gamma=0.99):\n",
    "        self.state_size = state_size\n",
    "        self.num_action = num_action\n",
    "        self.Q_values = np.zeros((state_size, state_size, num_action))  \n",
    "        self.eps_greedy = eps_greedy\n",
    "        self.eps_init = 1\n",
    "        self.eps = self.eps_init\n",
    "        self.eps_decay = 0.001  \n",
    "        self.learning_rate = 1\n",
    "        self.gamma = gamma\n",
    "        # mode\n",
    "        self.mode = mode\n",
    "        if mode == 'opt_init':\n",
    "            self.Q_values += 1\n",
    "            print('Q_value: {}'.format(self.Q_values.mean()))\n",
    "        elif mode == 'count':\n",
    "            # count\n",
    "            self.count_matrix = np.zeros((state_size, state_size))\n",
    "            print('count matrix: {}'.format(self.count_matrix.mean()))\n",
    "        elif mode.startswith('reward shift'):\n",
    "            self.reward_shift = float(mode.replace('reward shift ', ''))\n",
    "            print('reward shift {}'.format(self.reward_shift))\n",
    "        else:\n",
    "            print('no mode')\n",
    "\n",
    "    \n",
    "    def _decay_eps(self):\n",
    "        self.eps = max(0, self.eps - self.eps_decay)\n",
    "    \n",
    "    def act(self, state, random=False):\n",
    "        if self.mode == 'count':\n",
    "            self.count_matrix[state[0], state[1]] += 1\n",
    "\n",
    "        if random or (self.eps_greedy and np.random.random() < self.eps):\n",
    "            return np.random.randint(self.num_action)\n",
    "        argmax_action = np.argmax(self.Q_values[state[0], state[1]])\n",
    "        return argmax_action\n",
    "\n",
    "    def update_Q(self, transition):\n",
    "        state, action, next_state, reward, done = transition\n",
    "        argmax_action = np.argmax(self.Q_values[next_state[0], next_state[1]])\n",
    "\n",
    "        if self.mode.startswith('reward shift'):\n",
    "            reward  += self.reward_shift\n",
    "        elif self.mode == 'count':\n",
    "            reward += 1 / (self.count_matrix[state[0], state[1]] + 1) * 0.1\n",
    "\n",
    "        self.Q_values[state[0], state[1]][action] += self.learning_rate * (reward + \n",
    "                        self.gamma * self.Q_values[next_state[0], next_state[1]][argmax_action] - self.Q_values[state[0], state[1]][action])\n",
    "\n",
    "def rollout(agent, env, episode=10, eval=False):\n",
    "    reward_list = []\n",
    "    for _ in range(episode):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        rewards = 0\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            if not eval:\n",
    "                agent.update_Q([state, action, next_state, reward, done])\n",
    "            rewards += reward\n",
    "            state = next_state\n",
    "        reward_list.append(rewards)\n",
    "        if not eval:\n",
    "            agent._decay_eps()\n",
    "    return np.sum(reward_list)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    plot_curves = True # if false, plot heatmap\n",
    "    size = 20  # set the map size\n",
    "    print_every = 10\n",
    "\n",
    "    if plot_curves:\n",
    "        num_seed = 10\n",
    "        num_episode = 1000 \n",
    "        eval_episodes = 50  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02'] # 'opt_init', 'reward shift -0.1'\n",
    "    else:\n",
    "        num_seed = 1\n",
    "        num_episode = 1500\n",
    "        eval_episodes = 10  \n",
    "        mode_list = [r'$\\epsilon-greedy$', 'count', 'reward shift -0.02', 'reward shift -0.1'] # 'opt_init', \n",
    "    \n",
    "    result_all_list = []\n",
    "    for j, mode in enumerate(mode_list):\n",
    "        print('mode: {}'.format(mode))\n",
    "        result_seed = []\n",
    "        for seed in range(num_seed):\n",
    "            result = []\n",
    "            env = GridEnv(size=size)\n",
    "            agent = Agent(state_size=size, mode=mode)\n",
    "            for i in range(num_episode // print_every):\n",
    "                train_rewards = rollout(agent, env, episode=print_every)\n",
    "                eval_rewards = rollout(agent, env, eval=True, episode=eval_episodes)\n",
    "                print('training episodes: {}, train mean_rewards: {}, eval_rewards: {}, eps:{}'.format((i+1)* print_every,\n",
    "                                    train_rewards, eval_rewards, agent.eps))\n",
    "                result.append(eval_rewards)\n",
    "            result_seed.append(result)\n",
    "        \n",
    "        result_all_list.append(result_seed)\n",
    "\n",
    "        # plot heatmap\n",
    "        if not plot_curves:\n",
    "            plt.subplot(1,len(mode_list), j+1) \n",
    "            # normalize Q values\n",
    "            Q_values = agent.Q_values.max(axis=2).copy()\n",
    "            Q_max, Q_min = Q_values.max(), Q_values.min()\n",
    "            if Q_max == Q_min:\n",
    "                Q_values_norm = np.zeros(Q_values.shape)\n",
    "            else:\n",
    "                Q_values_norm = (Q_values - Q_min) / (Q_max - Q_min)\n",
    "            sns.heatmap(data=Q_values_norm, square=True, vmin=0, vmax=1) \n",
    "            plt.title(mode)\n",
    "    \n",
    "    if not plot_curves:\n",
    "        plt.show()\n",
    "    else:\n",
    "        x_axis = (np.arange(num_episode // print_every) + 1) * print_every\n",
    "        for i, mode in enumerate(mode_list):\n",
    "            if type(result_all_list[i][0]) == list:\n",
    "                array = np.array(result_all_list[i])\n",
    "                y_mean = array.mean(axis=0)\n",
    "                y_std = array.std(axis=0)\n",
    "                plt.plot(x_axis, y_mean, label=mode)\n",
    "                plt.fill_between(x_axis, y_mean - y_std, y_mean + y_std, alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(x_axis, result_all_list[i], label=mode)\n",
    "        plt.legend()\n",
    "        plt.title(r'Exploration in {} $\\times$ {} Grid World'.format(size, size))\n",
    "        plt.ylabel('Evaluation Returns')\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.show()\n",
    "\n",
    "        # save\n",
    "        np.save('grid_return_{}.npy'.format(GOAL), np.array(result_all_list))\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4955107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.79",
   "language": "python",
   "name": "py2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
